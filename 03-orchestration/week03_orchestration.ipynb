{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18fb1d1f",
   "metadata": {},
   "source": [
    "# An Intro to Workflow Orchestration with Prefect\n",
    "* Set of tools, that schedule and monitor the work:\n",
    "    * E.g. Machine Learning Pipeline, that we want to run every week, we put it on a schedule and if it fails we want to be able to see the issues that occured. There are a lot of places where a MAchine Learning Pipeline can fail. \n",
    "    * Workflow orchestration shall help us to deal with these failures.\n",
    "    ![prefect](prefect_01.png)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e9b367",
   "metadata": {},
   "source": [
    "## Negative Engineering\n",
    "90% of engineering time is speend on\n",
    "* Retries when APIs go down\n",
    "* Malformed Data\n",
    "* Notifications\n",
    "* Observability into failures\n",
    "* Condictional failure logic\n",
    "* Timeouts\n",
    "\n",
    "Prefect aims to reduce this time!\n",
    "Workflow orchestration is a set of features that help to reduce the time spend onthe above points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a447c73",
   "metadata": {},
   "source": [
    "## Introduction to Prefect\n",
    "Eliminating negative engineering\n",
    "\n",
    "* open source workflow orchestration\n",
    "* Python-based\n",
    "* Modern data stack\n",
    "* Native dask integration\n",
    "* Very active community\n",
    "* Prefect cloud/ Prefect server\n",
    "* Prefect Orion (Prefect 2.0) (currently beta-version available)\n",
    "\n",
    "* Basic example of the usage of Prefect:\n",
    "![prefect](prefect_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b440f73",
   "metadata": {},
   "source": [
    "**Next step: use the notebook from the previous week and convert it to a script, so that we can deploy it.**\n",
    "* We will use Prefect 2.0 for this tutorial! This needs to be explicitely installed: ```prefect==2.0b5```\n",
    "* Use ```requirements.txt```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd8b3df",
   "metadata": {},
   "source": [
    "# First Prefect Flow and Basic Concepts\n",
    "* It is quite normal that model accuracy drops over time, this is called *model drift*\n",
    "* To avoid this we can regularly retrain our model\n",
    "\n",
    "![model_drift](model_drift.png)\n",
    "\n",
    "* We already have a script that trains a model\n",
    "* Now we would like to put this on a schedule\n",
    "* Before putting the new model into production, we would like to compare it -> We can use mlflow for that\n",
    "* Install prefect: ```pip install prefect==2.0b5```\n",
    "* We now bring our training script to prefect. \n",
    "    * For that do ```from prefect import flow``` and add the decorator ```@flow``` around the ```main``` function\n",
    "    * Next: ```from prefect import flow, task``` and add the decorator ```@task``` around the ```add_features``` function\n",
    "    * This makes ```add_features``` a future and we need to add ```.result()```, when we call it\n",
    "* Using ```prefect orion start``` gives us the URL to a dashboard:\n",
    "```\n",
    "INFO:     Started server process [161608]\n",
    "INFO:     Waiting for application startup.\n",
    "INFO:     Application startup complete.\n",
    "INFO:     Uvicorn running on http://127.0.0.1:4200 (Press CTRL+C to quit)\n",
    "```\n",
    "![prefect start](prefect_start.png)\n",
    "\n",
    "* Each time we start a flow run, prefect updates its state to the API\n",
    "    * All the logs from the runs are visible through the API\n",
    "* \"Tasks are the unit of monitoring\", each task is observed by prefect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f80e31",
   "metadata": {},
   "source": [
    "# Remote Prefect Orion Deployment\n",
    "\n",
    "* Instructions: Hosting an Orion instance on a cloud VM: https://discourse.prefect.io/t/hosting-an-orion-instance-on-a-cloud-vm/967\n",
    "    * Start an instance/VM (as shown in week 01)\n",
    "    * Add necessary security\n",
    "        * Edit Inbound Rules: \n",
    "            * add http from everywhere (source: anywhere)\n",
    "            * add custom TCP, port range 4200 from everywhere (source: anywhere)\n",
    "            * add custom UDP, port range 4200 from everywhere (source: anywhere)\n",
    "            * add HTTPS from everywhere (source: anywhere)\n",
    "    * Go back to the instance and refresh\n",
    "    * ssh to this instance via the terminal: ```ssh -i <key> <name>@<ip>```\n",
    "    * Install necessary packages: ```pip install prefect==2.0b5```\n",
    "    * Set the UI_API_URL with : ```prefect config set PREFECT_ORION_UI_API_URL=\"http://<external-ip>:4200/api\"```\n",
    "    * Start Orion with: ```prefect orion start --host 0.0.0.0```\n",
    "    * From local machine, configure to hit the API with: ```prefect config set PREFECT_API_URL=\"http://<external-ip>:4200/api\"```\n",
    "    * The remote UI will be visible on :4200/\n",
    "* use ```prefect config view``` to check the configurations\n",
    "* use ```prefect config unset``` to unset the configurations (e.g. in case we made a mistake ...) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb911b4",
   "metadata": {},
   "source": [
    "# Deploy a prefect flow\n",
    "* storage:\n",
    "    * Our flows are stored somewhere\n",
    "    * We have to define a storage where our flows are saved\n",
    "    * Check the storage with ```prefect storage ls``` \n",
    "    ![prefect storage](prefect_storage.png)\n",
    "    * Create a new storage: ```prefect storage create```\n",
    "    ![prefect choose storage](prefect_storage_1.png)\n",
    "    * Choose the storage. In this example choose ```3``` for local storage\n",
    "    * Filepath: ```<HOME>/.prefect```\n",
    "    * Name: local\n",
    "* Add a deployment to our training script and save it as ```prefect_desploy.py```:\n",
    "```\n",
    "from prefect.deployments import DeploymentSpec\n",
    "from prefect.orion.schemas.schedules import IntervalSchedule\n",
    "from prefect.flow_runner import SubprocessFlowRunner\n",
    "from datetime import timedelta\n",
    "\n",
    "    # define deploymentspec\n",
    "DeploymentSpec(\n",
    "    flow=main,\n",
    "    name=\"model_training\",\n",
    "    schedule=IntervalSchedule(interval=timedelta(minutes=5)), #here in practice we would put 1 day, 1 week,...\n",
    "    flow_runner=SubprocessFlowRunner(),\n",
    "    tags=[\"ml\"]\n",
    ")\n",
    "```\n",
    "* In terminal: ```prefect deployment create prefect_deploy.py```\n",
    "* In terminal: ```prefect orion start```\n",
    "![deployment](deployment.png)\n",
    "* We can see our deployment, but the prefect server is not doing any of the compute, we need to specify where the training should run. The mechanism for this are agents and work queues.\n",
    "![work queues](workqueues.png)\n",
    "* create a workqueue\n",
    "![create work queue](create_workqueue.png)\n",
    "* We get a workflow id, which we can use, e.g.\n",
    "    * ```prefect work-queue preview cb95d191-d549-461d-87b0-9e1d3e298126``` to see all the scheduled runs:\n",
    "     ![workqueue_preview](workqueue_preview.png)\n",
    "* Now we spin up an agent. An agend looks for work that is to do: ```prefect agent start cb95d191-d549-461d-87b0-9e1d3e298126```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c95692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "ml-zoomcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22ef17ef",
   "metadata": {},
   "source": [
    "# Week 2\n",
    "\n",
    "## Important Concepts\n",
    "* ML experiment: The process of building an ML model\n",
    "* Experiment run: Each trial in an ML experiment\n",
    "* Run artifact: Any file that is associated with an ML run\n",
    "* Experiment metadata: All information related to the experimet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94d57b1",
   "metadata": {},
   "source": [
    "## What is Experiment Tracking?\n",
    "\n",
    "Experiment tracking is the process of keeping track of all the **relevant information** from an **ML experiment**, which includes:\n",
    "* Source code\n",
    "* Environment\n",
    "* Data\n",
    "* Model\n",
    "* Hyperparameters\n",
    "* Metrics\n",
    "* ...\n",
    "\n",
    "What exactly the 'relevant information' is, depends on the specific experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eee256",
   "metadata": {},
   "source": [
    "## Why is Experiment Tracking so important\n",
    "3 main reasons\n",
    "* Reproducability\n",
    "* Organization\n",
    "* Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9540aa",
   "metadata": {},
   "source": [
    "## MLflow\n",
    "* 'An open source toll for the machine learning lifecycle'\n",
    "* Python package, that contains 4 main modules:\n",
    "    * Tracking\n",
    "    * Models\n",
    "    * Model Registry\n",
    "    * Projects\n",
    "* Here we focus on tracking\n",
    "    * MLflow tracking module allows you to organize your experiments into runs, and keep track of\n",
    "        * Parameters\n",
    "        * Metrics\n",
    "        * Metadata\n",
    "        * Artifacts\n",
    "        * Models\n",
    "    * Along with this information, MLflow automatically logs extra information about the run:\n",
    "        * Source code\n",
    "        * Version of the code (git commit)\n",
    "        * Start and end time\n",
    "        * Author"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ffabeb",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "* ```pip install mlflow```\n",
    "* typing ```mlflow``` shows the options you have:\n",
    "![mlflow](mlflow.png)\n",
    "* Have a look at the ```ui``` option:\n",
    "    * ```mlflow ui```\n",
    "    * This runs mlflow ui locally\n",
    "    * This gives you access to the experiments via the browser\n",
    "![mlflow](mlflow_ui_terminal.png)\n",
    "![mlflow](mlflow_ui.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d1890",
   "metadata": {},
   "source": [
    "## Example: How to add loging to a Jupyter Notenbook\n",
    "* Create conda environment: ```conda create --name exp-tracking-env python=3.9```\n",
    "* Activate the environment: ```conda activate exp-tracking-env```\n",
    "* Install the requirements: ```pip install -r requirements.txt```\n",
    "* Start mlflow uri: ```mlflow ui --backend-store-uri sqlite:///mlflow.db```\n",
    "    * The option ```backend-store-uri``` here means that we want to store all the artifacts and metadata in an sqlite database\n",
    "    * Copy the notebook mlops-zoomcamp/01-intro/duration-prediction.ipynb\n",
    "    * Create a kernel from the environment: ```conda install -c anaconda ipykernel```, ```python -m ipykernel install --user --name=exp-tracking-env```\n",
    "    * Open the notebook and choose the kernel ```exp-tracking-env```\n",
    "    * Add this to the notebook:\n",
    "    ```import mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")```\n",
    "    * To track an experiment add\n",
    "    ```with mlflow.start_run():```\n",
    "      Then everything inside the ```with statement``` will be associated with the current run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d714404",
   "metadata": {},
   "source": [
    "## Experiment Tracking with MLflow\n",
    "* Add paramter tuning to the notebook\n",
    "    * Use a second model as example: xgboost\n",
    "    * Use hyperopt for hyperparamtertuning\n",
    "    * Documentation for hyperopt: https://hyperopt.github.io/hyperopt/getting-started/search_spaces\n",
    "* Show how it looks in MLflow\n",
    "    * Different visualisation possibilities: Parallel Coordinates Plot, Scatter Plot, Contour Plot\n",
    "    * Possibility to filter results, e.g. by tags\n",
    "* Select the best one\n",
    "    * One way to select the best model is to sort the results by the metric\n",
    "    * Also consider: training time, model size\n",
    "* Autolog\n",
    "    * Works only with certain frameworks: mlflow.org/docs/latest/tracking.html#automatic-logging\n",
    "    * Enables us to log a lot of information automatically with less code - additional logging maybe necessary\n",
    "    * For xgboost: ```mlflow.xgboost.autolog()```\n",
    "        * This saves automatically a lot of useful paramters and artifacts\n",
    "* Use again the notebook from the previous sesion ```duration-prediction.ipynb```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1f6804",
   "metadata": {},
   "source": [
    "# Model Management\n",
    "![ml_lifecycle](ml_lifecycle.png)\n",
    "(https://neptune.ai/blog/ml-experiment-tracking)\n",
    "* After deploying the model we may realize that the model needs to be updated\n",
    "* Once we deploy the model, the prediction - monitoring stage starts\n",
    "* As for experiment tracking the way how we manage them can be automized\n",
    "    * E.g. we could manage our models using different folder and filenames. This has several disadvantages:\n",
    "        * it is very error prone \n",
    "        * there is no versioning\n",
    "        * there is no model lineage\n",
    "    * Alternatively we can use mlflow to manage our models\n",
    "        * the most simple way to save a model is: ```mlflow.log_artifact(local_path=\"models/lin_reg.bin\", artifact_path=\"models_pickle/\")```, Note: for me this did not work, but only ```mlflow.log_artifact(local_path=\"models/lin_reg.bin\")```\n",
    "        * better way to save the models:\n",
    "        ```\n",
    "        with mlflow.start_run():\n",
    "            best_params =  {'learning_rate': 0.20905792515510074,\n",
    "                            'max_depth': 7,\n",
    "                            'min_child_weight': 0.5241500975917085,\n",
    "                            'objective': 'reg:squarederror',\n",
    "                            'reg_alpha': 0.13309121698466933,\n",
    "                            'reg_lambda': 0.11277257081373988,\n",
    "                            'seed': 42}\n",
    "            mlflow.log_params(best_params)\n",
    "        \n",
    "            booster = xgb.train(\n",
    "                # paramters are passed to xgboost\n",
    "                params=params,\n",
    "                # training on train data\n",
    "                dtrain=train,\n",
    "                # set boosting rounds\n",
    "                num_boost_round=100,\n",
    "                # validation is done on validation dataset\n",
    "                evals=[(valid, 'validation')],\n",
    "                # if model does not improve for 50 methods->stop\n",
    "                early_stopping_rounds=50\n",
    "            )\n",
    "        \n",
    "            # make predictions\n",
    "            y_pred = booster.predict(valid)\n",
    "            # calculate error\n",
    "            rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "            # log metric\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "        \n",
    "            # log the model\n",
    "            mlflow.xgboost.log_model(booster, artifact_path=\"models_mlflow\")\n",
    "        ```\n",
    "        * Note: We have to disable the autolog, else the model will be saved twice: ```mlflow.xgboost.autolog(disable=True)```\n",
    "* Additionally we should log the preprocessor as an artifact\n",
    "* MLflow ui also shows us how to make predictions\n",
    "    * under ```models_mlflow``` examples for spark and pandas dataframe predictions are shown, with the specific model id\n",
    "    * we can load the model by the model id and usee it to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8132c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-tracking-env",
   "language": "python",
   "name": "exp-tracking-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
